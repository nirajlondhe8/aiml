{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOswnDEqivzoHGllKK40lk4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirajlondhe8/aiml/blob/main/exercise/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIUntKu0LNbV",
        "outputId": "e77c6a13-f121-4700-8965-fe18bc39363e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500 completed\n",
            "Synthetic data at epoch 500:\n",
            "[[-0.9999982   0.99959975  0.9999958   0.09571046 -0.8212809   0.99827224\n",
            "   0.36365035 -0.99999905 -0.999624   -0.9999877  -0.9744219  -0.999073\n",
            "   0.9997352  -0.9960045  -0.99999857 -0.9999985  -0.12200284 -0.9992536\n",
            "   0.81963646 -0.9998412  -0.9985361   1.          0.99627    -0.99997354\n",
            "  -0.16603185  0.5604886  -0.9999579   0.9711556  -0.8013773  -0.9923729\n",
            "  -0.99964154  0.35662308 -0.99999374 -0.99543303 -1.          0.9859635 ]\n",
            " [ 0.7731209  -0.45191684  0.998036    0.9783854  -0.17855535  0.97345996\n",
            "   0.00179919  0.7948637  -0.96982956 -0.9612942  -0.73685247 -0.948113\n",
            "   0.9901937   0.99459237 -0.98920685 -0.43077275  0.6319911  -0.90899956\n",
            "   0.63764966 -0.9943583   0.85877347  0.99766594 -0.6133064  -0.6199436\n",
            "  -0.9500699   0.9585462  -0.9389383  -0.05017869  0.82420015 -0.97865677\n",
            "  -0.00542869  0.84137917 -0.8899688  -0.95044696 -0.9631155  -0.11406729]\n",
            " [ 0.7648797   0.4423324  -0.91263354 -0.7784782   0.97187024 -0.6258441\n",
            "   0.9116445  -0.9702108  -0.8601984   0.9975915  -0.910505   -0.24638905\n",
            "  -0.65874285 -0.98256594  0.96738577  0.85008293 -0.77067745 -0.9877555\n",
            "   0.46438125 -0.76619196  0.9269744  -0.02546951  0.9428763  -0.85534585\n",
            "  -0.9628706   0.85123324 -0.33976826  0.9969476  -0.38429436  0.3940018\n",
            "  -0.68732464  0.98151845 -0.1654275   0.8517476  -0.8692605   0.19225074]\n",
            " [-0.97734565  0.84526265  0.12205435 -0.99740916  0.96122974 -0.9225512\n",
            "   0.8752949  -0.99764943 -0.9342488   0.67333174  0.46470985 -0.4666345\n",
            "  -0.25473022 -0.9992396   0.63205266 -0.9689622  -0.99342334 -0.6058954\n",
            "   0.91294944 -0.9326924  -0.9835875   0.98856807  0.7926047  -0.9703418\n",
            "  -0.80072176  0.36342368 -0.98669887  0.9984482  -0.894382    0.6689327\n",
            "  -0.9752905  -0.9107848  -0.9226222  -0.5418233  -0.6888453   0.98655325]\n",
            " [-0.5657019  -0.99862075 -0.95552844 -0.9977839  -0.9939515  -0.9837042\n",
            "   0.99978495  0.8608954   0.9825825  -0.63062435 -0.99945974  0.6211509\n",
            "  -0.9849727  -0.93629277  0.97555244  0.90659785 -0.98137605 -0.23237729\n",
            "   0.99885035  0.99973226  0.9994162  -0.92370164  0.68156016 -0.9981081\n",
            "  -0.56638855 -0.42216405  0.99346256  0.99996847  0.1999954  -0.00881182\n",
            "  -0.37567115  0.74823457 -0.99424756  0.9135949   0.9998595  -0.37914294]]\n",
            "Epoch 1000 completed\n",
            "Synthetic data at epoch 1000:\n",
            "[[-0.76187325  0.9999879  -1.         -0.9989001  -1.         -1.\n",
            "  -1.         -1.          0.8326706  -0.95403594  0.9999973  -0.00608572\n",
            "   1.          0.8758395  -0.9999485   0.99997795 -1.          0.9999515\n",
            "  -0.9999992  -0.99935204 -1.          1.         -0.9996461  -0.9999944\n",
            "   1.         -0.9999989  -1.          0.81933516 -0.9998132   1.\n",
            "   0.8940662   1.         -0.9417139   0.99999905  1.          0.999987  ]\n",
            " [ 0.73801756  0.9999963  -0.9987262  -0.7813576  -0.9997906   0.9701457\n",
            "  -0.98970425  0.96386415 -0.94265765 -0.99589145  0.9987269  -0.9999219\n",
            "   0.9999963   0.94501907 -0.9976745   0.9792192  -0.9999922   0.99993\n",
            "  -0.13903534 -0.9999795  -0.97078866  1.          0.9937378   0.99981815\n",
            "   0.9999961   0.58716714 -0.9997422  -0.6609764  -0.99940634  0.9083184\n",
            "  -0.47039312  0.9999394   0.9369101   0.97886723  0.9997525   1.        ]\n",
            " [ 0.9999614   0.99894875 -0.90647614  0.99999815 -0.293216   -0.64733195\n",
            "   0.19960691 -0.99969053 -0.9999997  -0.90003675 -0.9886113  -0.50989455\n",
            "   0.99889475  0.35696602  0.99335927  0.8367173   0.9994508   1.\n",
            "  -0.18040836  0.998594    0.9916524  -0.9882395   0.36501738 -0.2905613\n",
            "  -0.9950195  -0.9589951   0.99881214  0.83600235  0.80872655 -0.68159074\n",
            "   0.9877657  -0.99871206  0.8313252   0.999536   -0.99799603  0.82315487]\n",
            " [ 0.9999594   0.95226175  0.87844306  0.9995758   0.3525793  -0.99157906\n",
            "  -0.5952957  -0.99892515  0.9739357  -0.9999997   0.9094682   0.9960655\n",
            "   0.9999902  -0.9966322   0.9993089   0.9996872   0.99963033  0.998001\n",
            "  -0.9813176   0.99997854 -0.9995683   0.9876685  -0.9999219  -0.99172056\n",
            "   0.95955914  0.5975152  -0.0189475   0.9999237   0.99533635  0.9994906\n",
            "  -0.06648736 -0.999998    0.7466929   0.98971885 -0.927179    0.42285067]\n",
            " [-1.          0.65468735  0.9995153   0.9921657   0.9962402   0.99997115\n",
            "   0.94536763  0.99554455  0.56818056  0.9998217  -0.9999818  -0.9987901\n",
            "   0.9999909  -0.9996471   0.9999995  -0.99891776 -1.         -1.\n",
            "   0.9116812  -0.760984   -0.8090637  -0.85143     1.          0.99951446\n",
            "   0.995804   -0.99621135 -0.99745274 -0.9999988  -0.9994356  -0.99999315\n",
            "   1.         -0.99913675 -0.9999279   0.99990165  0.99920034 -0.9994876 ]]\n",
            "Epoch 1500 completed\n",
            "Synthetic data at epoch 1500:\n",
            "[[-1.          0.7622692   1.          0.99985355 -1.         -1.\n",
            "  -0.9986955  -1.         -1.          0.9999273  -1.         -0.9999938\n",
            "   0.41408753  1.          0.8262951  -0.899032    0.98888105 -1.\n",
            "   0.99999017  0.9974929   0.9999677   0.9945306   0.41981518 -1.\n",
            "  -1.         -1.          1.          1.         -0.9998922   0.99909794\n",
            "  -1.         -1.          1.          1.          0.84353936  0.9999843 ]\n",
            " [-0.9999309   0.99999696  0.9996879   0.9964531  -0.9989835  -0.9999995\n",
            "  -0.9999733   0.99999875 -0.0120142  -0.17604172 -0.9999154   0.9377345\n",
            "  -0.9920131  -0.6794938   0.5310857   0.99943095  0.9999667   0.44453594\n",
            "  -0.46513888 -0.99686474  0.9987532  -0.98038363  0.8714842  -0.9785104\n",
            "  -1.         -0.9976977   0.9979783   0.29542762  0.30770418  0.9995289\n",
            "  -0.99997556  0.9994264   0.99999964  0.9999912   1.          0.9999829 ]\n",
            " [-1.          0.6983557  -0.99978334  1.          0.9997188  -0.9297329\n",
            "  -0.98474985 -0.99999964 -0.99999833 -0.89563257 -0.9965321  -0.96840733\n",
            "   0.9970283  -0.46913433  0.98524904  0.99966574 -0.99971837  0.9759661\n",
            "   0.9999997   0.9982856   1.         -0.99999976 -0.9933435  -0.99999845\n",
            "  -0.9999882   0.9993922   0.99999046  0.97361517 -0.9975417  -0.99999905\n",
            "  -0.9999994  -1.          1.         -0.66631407 -0.7493866   0.02437716]\n",
            " [ 0.5902243  -0.94841576  0.99967235  0.9997963  -0.97932833  0.99969494\n",
            "  -0.93153816 -0.68769056 -0.9999486  -0.21552446  0.2230243   0.9878042\n",
            "   0.9999973   0.96337736  0.97354406  0.25126317  0.9493644  -0.9999996\n",
            "  -0.53597695 -0.8737659  -0.51895714 -0.6430999  -0.99988323 -1.\n",
            "  -0.98919076  0.7722491   1.          1.          0.9949889   0.42550296\n",
            "   0.98710865 -1.          1.          1.          0.8837074   0.9966077 ]\n",
            " [-0.998161   -0.922297    0.9974146  -0.99999183  1.         -0.99969035\n",
            "  -0.98529476  0.99993616  0.42773035 -0.9983967   0.13400854 -1.\n",
            "  -0.998941    1.          1.          0.9657965  -0.9999431   0.9852602\n",
            "   1.          1.          0.99645984 -1.         -1.          1.\n",
            "  -0.9890986  -0.9999979  -0.99575555  0.9999956  -0.99956244 -0.999989\n",
            "  -0.99976283 -0.9999811  -0.9999786  -0.961942   -1.         -0.89750534]]\n",
            "Epoch 2000 completed\n",
            "Synthetic data at epoch 2000:\n",
            "[[-0.9999956  -0.9990281   1.          0.9997189   1.         -0.91363347\n",
            "   0.9949158  -1.         -1.          0.4244715   0.53487873  1.\n",
            "  -1.          0.9997561   0.8038484   1.          1.         -0.9790651\n",
            "  -1.          1.         -1.         -0.9440598   1.         -1.\n",
            "   0.9999883  -1.         -1.         -0.9999997  -1.         -0.99977785\n",
            "  -0.7508851  -1.         -0.9348389   1.         -1.         -1.        ]\n",
            " [-1.          0.99940425  1.         -0.8195632  -0.94778436 -0.982761\n",
            "  -1.         -0.9999994  -0.9807487   0.9836314   0.99880016  0.9999995\n",
            "  -0.9830883   0.9994035  -0.99935     0.99967235  0.9983555  -0.99860924\n",
            "  -0.9986423   0.99999255 -1.         -0.99539775  0.83770233 -0.9997654\n",
            "  -0.9999919  -1.         -1.         -0.9999807  -0.9999402  -0.99999964\n",
            "  -0.99981445  0.99999964  0.4789143  -0.98428905  0.88306004  0.9991731 ]\n",
            " [-0.9999997  -0.9999958  -0.9770423  -0.9071156  -0.95141345  0.9991365\n",
            "  -0.525859   -1.         -1.         -0.9638326   0.99816906  0.99924237\n",
            "   0.8909916  -0.999936   -0.57654124  1.          0.8607864  -0.17638366\n",
            "   1.         -0.9468583  -0.9667767   0.9604411   0.01743402 -0.9812377\n",
            "  -0.9999971   0.99983436  0.3250944  -0.9998963  -0.9999124  -0.9995781\n",
            "  -1.         -1.          0.8574785  -1.          0.5198344  -0.9994026 ]\n",
            " [ 0.99999946 -1.         -0.99554455 -0.9871994   0.9992031   0.5108598\n",
            "   0.99993336 -0.99992836 -0.999875   -0.9986101   0.9907164   1.\n",
            "  -0.9894248  -0.9999709   1.          1.          0.99973804 -1.\n",
            "   0.8159578   0.44585383 -0.9999994  -0.9986014  -0.99999833 -0.9931106\n",
            "  -0.7057398  -0.60097694  0.9999975  -0.68955934 -0.99911225  0.9999758\n",
            "   0.99912065 -1.          0.96694213  1.         -0.9999994  -1.        ]\n",
            " [-0.99999464  0.9995333  -1.         -0.99999803  1.          0.841062\n",
            "   1.          1.         -1.         -0.9988846  -0.9960309  -1.\n",
            "   1.          0.9999987  -0.99364305 -0.825274    0.9793185  -0.9999834\n",
            "  -1.          0.9999499  -1.         -0.91317385  1.          1.\n",
            "   1.          0.9982822  -1.          1.         -1.          1.\n",
            "  -0.8510627  -1.          0.9853963   1.          1.          0.76714635]]\n",
            "Epoch 2500 completed\n",
            "Synthetic data at epoch 2500:\n",
            "[[-0.9986788   0.99898016 -0.9999995   0.9999034   1.          1.\n",
            "   1.         -1.          1.          1.          1.         -0.25993264\n",
            "  -1.         -1.         -0.81915665 -1.          1.          0.99999934\n",
            "  -1.         -1.         -1.         -0.99678713  1.         -1.\n",
            "  -1.         -1.          1.          0.5941525  -1.          1.\n",
            "  -1.          0.9999737  -0.9999998  -0.999872   -1.         -0.9999982 ]\n",
            " [-1.          1.          0.99999696 -0.9999979  -0.49522817 -0.99999636\n",
            "  -0.99999934 -0.9999949   1.         -0.99999803  0.9998919   0.9977369\n",
            "   1.         -0.999874    1.         -0.9998462   1.          0.97950333\n",
            "  -0.96902496 -0.99999523 -1.          0.9994828   1.         -0.9975913\n",
            "  -1.         -1.          0.9999283   0.99998844 -1.          0.9987076\n",
            "   0.7626401   0.9999925  -0.9999507   0.97142315  0.99999875  0.9999988 ]\n",
            " [-1.         -0.99267226 -0.9981622   0.99999946 -0.95944786  0.99999726\n",
            "  -0.9999634  -1.         -1.         -0.44257098 -0.57929474 -0.9994946\n",
            "   0.5995916  -1.          1.          0.9999823   0.99769837 -0.99949414\n",
            "   1.         -0.9988396  -0.9966173   0.9988033   1.          0.99997216\n",
            "  -1.         -0.13623177  0.8036275  -0.9990981  -1.          0.99780506\n",
            "  -0.9999971  -1.          0.9999929  -1.         -0.9999196  -0.99980766]\n",
            " [-0.91554356 -0.9999997  -1.         -0.9994333   1.          0.99986935\n",
            "   1.         -0.990734    1.          1.         -1.          0.9999837\n",
            "  -1.         -1.          0.9961963   0.9999945   0.5126054   0.9999115\n",
            "  -0.9585048  -1.          0.23459943 -1.         -0.9999958  -0.57588065\n",
            "  -1.          1.          0.8536712   0.10205775 -0.7595266   1.\n",
            "  -0.26851422 -1.         -0.9989561   0.99999774 -1.         -1.        ]\n",
            " [ 0.8462848   0.82861745 -0.9950638   0.9999998   1.          0.99688846\n",
            "   0.99999285 -0.5025589  -1.          0.9101283   1.          0.9948919\n",
            "  -0.8086177   0.22648247 -0.9999767  -0.9519284   1.         -0.99989194\n",
            "  -1.         -0.9997863   0.9965651   0.9913295  -0.99999714  0.9999567\n",
            "  -0.999734    1.         -1.          1.         -0.57200414  1.\n",
            "  -0.9999859   0.9999763   0.99999934  0.99991834  0.9999981  -1.        ]]\n",
            "Epoch 3000 completed\n",
            "Synthetic data at epoch 3000:\n",
            "[[-0.99999285  1.         -1.         -1.          1.          1.\n",
            "   1.         -0.93916124  1.          1.          1.         -0.9997996\n",
            "  -1.         -0.75342697  0.1910556  -1.          1.         -1.\n",
            "   1.          0.99996626  1.         -1.          1.         -1.\n",
            "   1.         -1.          1.         -1.          0.9985052   0.9999939\n",
            "  -1.          0.9999916  -0.9931817   0.9989255  -1.         -1.        ]\n",
            " [-0.99999964  1.          0.8832831  -1.          0.9999591  -1.\n",
            "   0.9999973   0.30941767  0.9623125  -0.7209777   1.          1.\n",
            "   0.9996266   1.          1.         -0.99939585  1.         -0.8000917\n",
            "   1.          1.         -0.8725324   0.9933388   1.         -0.9999853\n",
            "  -0.26412085 -1.          0.4702158  -0.99999964  0.9999924  -0.99995023\n",
            "  -0.98607695  0.9999234   0.9974279   0.98077804  1.          1.        ]\n",
            " [-1.          0.9101194   1.          0.99999934 -1.          1.\n",
            "   0.9643794  -0.02030871 -0.99892575  1.         -0.16808815 -0.9854444\n",
            "   0.9992335  -0.9682283  -0.48941842 -0.6402741  -0.9999983  -1.\n",
            "   1.         -1.          0.9839096   0.99979573  1.         -0.99996495\n",
            "  -0.9999954  -0.58393085  0.9541226   0.90219676  0.99999416  1.\n",
            "  -0.99869066 -1.          0.99999833  0.1651113  -1.         -0.9876267 ]\n",
            " [-0.99999833 -0.9999501  -1.         -0.8276749   0.99997365  0.99944097\n",
            "   1.          1.          1.          1.         -1.         -0.99909234\n",
            "  -0.90482664 -0.9996687  -0.9999982   1.         -0.65349394 -0.99999195\n",
            "   0.9861463  -0.9999368   0.9970081  -1.         -1.         -1.\n",
            "  -0.9999617   0.9999928   1.          1.          1.          1.\n",
            "  -0.993449   -1.         -0.93469775  0.999977   -0.9999137  -1.        ]\n",
            " [-0.88415587 -0.9978068  -1.          1.          0.9588055   0.93072426\n",
            "  -0.99996835  0.99882185 -0.99882305 -0.9999827   0.99731606  1.\n",
            "   1.         -0.04633494 -0.9999995   0.9999997  -0.9999697   1.\n",
            "   1.          0.19572961  0.9996398  -0.9972013  -1.         -0.9999584\n",
            "  -1.          1.         -0.9998849   1.          1.          0.9999973\n",
            "  -1.          1.          1.          0.99999917  1.         -1.        ]]\n",
            "Epoch 3500 completed\n",
            "Synthetic data at epoch 3500:\n",
            "[[ 1.          1.         -1.          0.9998777   1.         -1.\n",
            "   1.         -1.          1.          1.         -0.13578469 -1.\n",
            "  -1.         -1.          0.99999946  0.23972602  1.         -1.\n",
            "   1.          0.9999946   1.          1.          0.9731938  -0.99340117\n",
            "   1.          1.          1.          1.          0.99875087  1.\n",
            "  -1.         -0.9999506  -1.          1.         -0.99969304 -0.5483597 ]\n",
            " [ 1.          0.9956926   0.9999994  -0.99936086  0.9999957  -1.\n",
            "  -0.21487604 -0.99999064  0.9996385  -1.         -0.9997797   1.\n",
            "  -1.         -0.99900556  1.         -1.          0.99988383  1.\n",
            "   1.          1.          0.99822384  0.9999989   1.         -0.97841\n",
            "   0.9524536  -1.         -0.9999913  -0.99999905 -0.9998585  -1.\n",
            "   1.         -1.          0.98214334  0.99374825  1.          0.32096115]\n",
            " [ 0.8118997  -0.9760496   1.          1.         -0.9999145   1.\n",
            "  -1.         -1.          0.65479136  0.99997157  1.         -0.9999835\n",
            "   1.         -0.9994866   1.         -0.99903905 -0.9447708  -1.\n",
            "   1.         -0.92854774  1.         -1.          1.         -1.\n",
            "  -1.          1.          0.93621767  1.          0.3939234   0.42900193\n",
            "  -1.         -1.          1.         -0.9999648  -1.         -0.99999446]\n",
            " [-0.9999284  -0.99995196 -0.99999833  1.         -1.         -1.\n",
            "   1.          0.9999968   1.          1.         -1.          1.\n",
            "   0.96915686 -1.         -1.          1.          1.         -0.73891526\n",
            "  -1.         -0.9989394   0.99999905 -0.999916   -1.         -1.\n",
            "   0.999595    1.          1.          1.          0.94761986  1.\n",
            "  -1.         -1.         -1.          1.         -1.         -1.        ]\n",
            " [ 0.9999973  -1.         -1.          1.         -1.          0.99993914\n",
            "  -0.99994385 -0.9999697   0.9999953  -1.         -0.99969757  1.\n",
            "  -0.99387753  0.37692368 -1.          0.18547045 -1.          1.\n",
            "   0.9926749  -1.         -1.         -0.43879083 -1.         -1.\n",
            "   0.9984518   1.         -0.9995246   0.9999354   0.9981562   0.9999587\n",
            "  -0.9993907   1.          1.          1.         -0.9961727  -1.        ]]\n",
            "Epoch 4000 completed\n",
            "Synthetic data at epoch 4000:\n",
            "[[ 1.          1.         -1.         -1.          1.          1.\n",
            "   0.99995303 -1.          1.          1.          1.         -1.\n",
            "  -1.         -1.          1.         -1.          1.         -1.\n",
            "   0.99996954  0.99999887 -0.0917447   1.         -1.         -1.\n",
            "   0.9925441   1.          0.99932116  1.          0.99999964  1.\n",
            "  -1.         -1.         -0.9999947   1.         -1.          1.        ]\n",
            " [ 0.6018115  -0.9999267   0.999688   -1.          1.          1.\n",
            "   1.         -1.          1.         -0.9997256   0.99999744  0.9999715\n",
            "  -1.         -1.          1.         -1.          1.          0.99999946\n",
            "   1.          0.9999799  -1.          0.72642386  1.         -1.\n",
            "  -0.987412   -0.9985344   0.99974954 -1.         -1.         -0.5318576\n",
            "   1.         -1.         -0.7986968   0.99759996 -0.995016    0.827263  ]\n",
            " [ 0.9995678  -1.          1.          1.          0.9999995   1.\n",
            "  -1.         -0.9999947   0.99679875  1.          0.99999136 -0.99999267\n",
            "   1.         -0.9999907   0.99987996 -1.          0.7399453  -1.\n",
            "   1.          1.          1.         -1.          1.         -1.\n",
            "  -1.          1.          0.4287609   0.99992967  1.          0.99990743\n",
            "  -0.9999992  -1.          1.          0.9999585  -1.         -0.16824408]\n",
            " [-0.89061475  1.         -1.          1.         -1.         -0.99999887\n",
            "   0.68019074 -1.         -0.9921969   1.         -1.          1.\n",
            "   1.         -1.          1.          1.          1.         -0.5917236\n",
            "  -1.          0.99443185 -1.          0.99989027 -1.         -0.84278303\n",
            "  -1.          1.         -0.99059147  1.          1.          0.9999086\n",
            "  -1.         -1.          0.9983493  -0.995473   -0.999685    0.9971336 ]\n",
            " [-0.99996793 -0.6611728  -1.          1.         -1.          0.99996334\n",
            "  -1.         -0.9906219  -0.9703702  -0.9999308   0.9958316   1.\n",
            "   1.          1.          0.9999853  -1.         -1.          1.\n",
            "  -0.9999497  -1.         -1.          1.         -1.         -1.\n",
            "  -0.9999897  -1.         -1.          1.          1.          1.\n",
            "  -0.9438485   1.          1.          0.9999381  -0.99999356  0.98365444]]\n",
            "Epoch 4500 completed\n",
            "Synthetic data at epoch 4500:\n",
            "[[ 1.          0.9998764  -1.         -1.          1.          1.\n",
            "   1.         -0.9993564   0.72213286  1.          1.         -0.99995553\n",
            "  -1.         -1.          1.          1.          1.         -1.\n",
            "   0.9999997  -1.         -1.          1.         -1.         -1.\n",
            "   1.          1.         -0.9734615  -1.          1.          1.\n",
            "  -1.         -0.9999958  -1.          1.          0.5184673   1.        ]\n",
            " [-1.         -1.         -0.99878484 -1.          0.99708575  1.\n",
            "   1.          0.99999774  0.9937087  -0.9999993   0.99998957  0.9999967\n",
            "  -1.         -0.9662965   1.         -1.          0.99993724 -1.\n",
            "   0.98594904 -1.         -1.         -0.9999986   1.         -0.99996203\n",
            "   0.9995605   1.          0.9999984  -0.99998116 -1.          0.8767517\n",
            "   0.9999984  -1.         -0.99991775  0.99785954 -1.          0.9998542 ]\n",
            " [ 0.99846137 -1.          1.          0.97219956  0.99998313  1.\n",
            "  -1.         -0.9999698   1.          1.         -1.          0.9999449\n",
            "   1.          1.          0.99168587 -0.99999034 -0.99904346 -1.\n",
            "   1.          1.          1.         -1.         -0.99999535 -1.\n",
            "  -1.          1.         -0.9615878   0.15403691  1.          1.\n",
            "   0.999889    0.98371774  1.          1.         -1.          0.9992364 ]\n",
            " [ 0.4769394   1.         -1.          1.         -1.         -0.9999997\n",
            "   0.9963039  -0.99998564  0.9958005   1.         -1.          0.999974\n",
            "   1.         -1.          0.99991626  1.          0.9991562   0.9999259\n",
            "  -0.9999985   1.         -1.          1.         -1.         -1.\n",
            "  -1.          1.          0.85820335  1.          0.9998753   0.06847932\n",
            "  -1.         -1.          0.99996746 -0.9999678   1.         -0.99972564]\n",
            " [ 0.8192914   1.          0.9992776   1.         -1.         -1.\n",
            "  -1.          1.          1.         -0.8219402   0.7469778   1.\n",
            "   1.          1.         -1.         -1.         -1.          1.\n",
            "  -0.8258612  -1.          0.93860847  1.         -1.         -1.\n",
            "   0.9493698  -0.96634257 -1.          1.          0.7698975   1.\n",
            "   0.42150342 -0.99998444  1.         -0.9529681  -1.          0.6025387 ]]\n",
            "Epoch 5000 completed\n",
            "Synthetic data at epoch 5000:\n",
            "[[ 1.         -0.9999614  -1.         -1.          1.          1.\n",
            "   1.         -1.          1.          1.         -1.          0.9999928\n",
            "  -1.         -1.          1.          1.         -0.999929   -1.\n",
            "   1.         -1.         -1.          1.         -1.         -0.999312\n",
            "   1.          1.         -1.          1.          1.         -1.\n",
            "  -1.         -0.99999684 -0.75053155 -0.9997546  -0.9937732   1.        ]\n",
            " [-1.          0.90971684  0.9999318  -1.         -0.99999505  1.\n",
            "   1.          0.9999931  -1.         -1.         -0.90624297  0.99999785\n",
            "  -1.         -1.          1.         -1.          0.9633001  -1.\n",
            "   1.         -0.9999992  -0.964689   -1.          1.          0.95467305\n",
            "   0.99999905 -0.3067522  -1.          1.         -0.9999783  -0.78653806\n",
            "   0.999993   -1.         -0.9997489   0.3432263  -1.         -0.9999995 ]\n",
            " [ 0.99942917 -1.          1.          0.99292374  1.          0.9999986\n",
            "  -1.         -0.99999917  0.9999759   1.         -1.          1.\n",
            "   1.          1.          1.         -1.         -0.99990654 -1.\n",
            "   1.          1.          1.         -1.         -1.         -1.\n",
            "  -1.          0.6769618  -1.          0.9999967   0.99999964  1.\n",
            "  -1.          0.99365675  0.9986651   0.99699336 -1.          0.9999995 ]\n",
            " [-0.9719183   1.         -1.          0.9900501  -1.         -1.\n",
            "   0.99986523 -1.          1.          1.         -1.          1.\n",
            "   1.         -0.99996305  0.94064444  1.         -0.9998574   0.9661021\n",
            "  -1.          1.         -1.          1.         -1.          0.03468435\n",
            "  -1.          1.          0.9985066  -0.9999839   1.          0.8705209\n",
            "  -1.          0.9993652   0.99693686 -1.          0.9998225  -0.9999984 ]\n",
            " [-0.9999879   1.         -0.9999996  -0.97698504 -1.         -1.\n",
            "  -1.         -1.          1.         -1.         -1.          1.\n",
            "   1.          1.         -0.99785954 -1.         -1.          1.\n",
            "   0.9991285  -1.          1.          0.9999928  -1.          0.9998579\n",
            "   1.         -0.42849848 -1.          1.          0.89720255 -0.9995892\n",
            "  -1.         -1.          0.9313149  -0.9999998  -1.         -1.        ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Generate Sample Data for Network Functions\n",
        "network_functions = ['gNB', 'AUSF', 'UDM', 'UDR', 'HSS', 'SMSC', 'PGW', 'SGW', 'eNB']\n",
        "n_samples = 1000  # Number of data points per network function\n",
        "\n",
        "# Initialize an empty dataframe\n",
        "data = pd.DataFrame()\n",
        "\n",
        "# Generate sample data for each network function\n",
        "for nf in network_functions:\n",
        "    data[f'{nf}_cpu_usage'] = np.random.normal(loc=50, scale=10, size=n_samples)  # Mean 50%, std dev 10%\n",
        "    data[f'{nf}_memory_usage'] = np.random.normal(loc=30, scale=5, size=n_samples)  # Mean 30%, std dev 5%\n",
        "    data[f'{nf}_packet_loss'] = np.random.normal(loc=0.5, scale=0.1, size=n_samples)  # Mean 0.5%, std dev 0.1%\n",
        "    data[f'{nf}_latency'] = np.random.normal(loc=10, scale=2, size=n_samples)  # Mean 10ms, std dev 2ms\n",
        "\n",
        "# Prepare the dataset (flatten the columns)\n",
        "X_train = data.values\n",
        "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)  # Normalize the data\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Step 2: Build the GAN\n",
        "\n",
        "# Generator\n",
        "def build_generator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(128, input_dim=100))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dense(256))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dense(input_dim, activation='tanh'))  # Output layer matches data dimensionality\n",
        "    return model\n",
        "\n",
        "# Discriminator\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(256, input_dim=input_dim))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(128))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Loss and Optimizers\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "# Initialize Generator and Discriminator\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "# Step 3: Train the GAN\n",
        "\n",
        "EPOCHS = 5000\n",
        "BATCH_SIZE = 128\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "# Define training steps\n",
        "@tf.function\n",
        "def train_step(real_data):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_data = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(real_data, training=True)\n",
        "        fake_output = discriminator(generated_data, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "# Training Loop\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for data_batch in dataset:\n",
        "            train_step(data_batch)\n",
        "\n",
        "        # Generate synthetic data after each epoch for visualization\n",
        "        if (epoch + 1) % 500 == 0:\n",
        "            print(f'Epoch {epoch+1} completed')\n",
        "            generate_and_save_data(generator, epoch + 1, seed)\n",
        "\n",
        "# Function to generate and save synthetic data\n",
        "def generate_and_save_data(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    # Show a few generated synthetic data points (first 5 rows)\n",
        "    print(f\"Synthetic data at epoch {epoch}:\")\n",
        "    print(predictions.numpy()[:5])  # Display first 5 synthetic samples\n",
        "\n",
        "# Prepare data for training (as TensorFlow Dataset)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(10000).batch(BATCH_SIZE)\n",
        "\n",
        "# Train the GAN\n",
        "train(train_dataset, EPOCHS)\n"
      ]
    }
  ]
}