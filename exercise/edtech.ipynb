{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNy7MeEBuhd7GnybxzpAT4A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirajlondhe8/aiml/blob/main/edtech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wwvd1HnCM-f",
        "outputId": "d4743d99-8703-444d-85c3-605c2c4c6440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube\n",
        "!pip install moviepy\n",
        "!pip install transformers\n",
        "!pip install torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import pytube\n",
        "import moviepy.editor as mp\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "# Check if a GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Download the video from YouTube\n",
        "def download_video(youtube_url, save_path='video.mp4'):\n",
        "    try:\n",
        "        yt = pytube.YouTube(youtube_url)\n",
        "        video = yt.streams.filter(res=\"720p\").first()\n",
        "        video.download(filename=save_path)\n",
        "        print(\"Video downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while downloading the video: {e}\")\n",
        "\n",
        "# Convert video to audio\n",
        "def convert_video_to_audio(video_path='video.mp4', audio_path='audio.wav'):\n",
        "    try:\n",
        "        video = mp.VideoFileClip(video_path)\n",
        "        video.audio.write_audiofile(audio_path)\n",
        "        print(\"Audio extracted successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while converting video to audio: {e}\")\n",
        "\n",
        "# Transcribe audio to text using Hugging Face\n",
        "def transcribe_audio(audio_path='audio.wav'):\n",
        "    try:\n",
        "        # Load ASR (Automatic Speech Recognition) pipeline from Hugging Face\n",
        "        asr_pipeline = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-large-960h\", device=device)\n",
        "        \n",
        "        # Load audio file as binary\n",
        "        with open(audio_path, \"rb\") as audio_file:\n",
        "            audio = audio_file.read()\n",
        "            transcription = asr_pipeline(audio)[\"text\"]\n",
        "        print(\"Audio transcription completed.\")\n",
        "        return transcription\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during audio transcription: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Analyze content and compare with key indicators\n",
        "def analyze_content(text):\n",
        "    indicators = {\n",
        "        \"Highly Effective\": \"Lesson plans reflect a thorough integration of State standards and the STEM School PBL Instructional Model.\",\n",
        "        \"Effective\": \"Lesson plans closely align to STEM PBL Instructional Model and State standards\",\n",
        "        \"Partially Effective\": \"Lesson plans are partially aligned to State standards, STEM PBL Instructional Model.\",\n",
        "        \"Ineffective\": \"Lesson plans are not readily available and/or do not align with State standards and STEM School PBL Instructional Model\"\n",
        "    }\n",
        "    \n",
        "    sentiment_analysis = pipeline('sentiment-analysis')\n",
        "    \n",
        "    results = {}\n",
        "    for key, indicator in indicators.items():\n",
        "        result = sentiment_analysis(text)\n",
        "        results[key] = result\n",
        "    \n",
        "    print(\"Content analysis completed.\")\n",
        "    return results\n",
        "\n",
        "# Main function to execute the process\n",
        "def main():\n",
        "    youtube_url = 'https://www.youtube.com/watch?v=ERIwByt4xc0&feature=youtu.be'\n",
        "    video_path = 'video.mp4'\n",
        "    audio_path = 'audio.wav'\n",
        "    \n",
        "    download_video(youtube_url, video_path)\n",
        "    convert_video_to_audio(video_path, audio_path)\n",
        "    text = transcribe_audio(audio_path)\n",
        "    analysis_results = analyze_content(text)\n",
        "    \n",
        "    print(\"Analysis Results:\")\n",
        "    for key, result in analysis_results.items():\n",
        "        print(f\"{key}: {result}\")\n",
        "\n",
        "# Run the main function\n",
        "main()\n"
      ],
      "metadata": {
        "id": "ARpN5FrkDKU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytube\n",
        "import moviepy.editor as mp\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "# Check if a GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Download the video from YouTube\n",
        "def download_video(youtube_url, save_path='video.mp4'):\n",
        "    try:\n",
        "        yt = pytube.YouTube(youtube_url)\n",
        "        video = yt.streams.filter(res=\"720p\").first()\n",
        "        video.download(filename=save_path)\n",
        "        print(\"Video downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while downloading the video: {e}\")\n",
        "\n",
        "# Convert video to audio\n",
        "def convert_video_to_audio(video_path='video.mp4', audio_path='audio.wav'):\n",
        "    try:\n",
        "        video = mp.VideoFileClip(video_path)\n",
        "        video.audio.write_audiofile(audio_path)\n",
        "        print(\"Audio extracted successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while converting video to audio: {e}\")\n",
        "\n",
        "# Transcribe audio to text using Hugging Face\n",
        "def transcribe_audio(audio_path='audio.wav'):\n",
        "    try:\n",
        "        # Load ASR (Automatic Speech Recognition) pipeline from Hugging Face\n",
        "        asr_pipeline = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-large-960h\", device=device)\n",
        "\n",
        "        # Load audio file as binary\n",
        "        with open(audio_path, \"rb\") as audio_file:\n",
        "            audio = audio_file.read()\n",
        "            transcription = asr_pipeline(audio)[\"text\"]\n",
        "        print(\"Audio transcription completed.\")\n",
        "        return transcription\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during audio transcription: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Analyze content and compare with key indicators\n",
        "def analyze_content(text):\n",
        "    indicators = {\n",
        "        \"Highly Effective\": \"Lesson plans reflect a thorough integration of State standards and the STEM School PBL Instructional Model.\",\n",
        "        \"Effective\": \"Lesson plans closely align to STEM PBL Instructional Model and State standards\",\n",
        "        \"Partially Effective\": \"Lesson plans are partially aligned to State standards, STEM PBL Instructional Model.\",\n",
        "        \"Ineffective\": \"Lesson plans are not readily available and/or do not align with State standards and STEM School PBL Instructional Model\"\n",
        "    }\n",
        "\n",
        "    sentiment_analysis = pipeline('sentiment-analysis')\n",
        "\n",
        "    results = {}\n",
        "    for key, indicator in indicators.items():\n",
        "        result = sentiment_analysis(text)\n",
        "        results[key] = result\n",
        "\n",
        "    print(\"Content analysis completed.\")\n",
        "    return results\n",
        "\n",
        "# Main function to execute the process\n",
        "def main():\n",
        "    youtube_url = 'https://www.youtube.com/watch?v=ERIwByt4xc0&feature=youtu.be'\n",
        "    video_path = 'video.mp4'\n",
        "    audio_path = 'audio.wav'\n",
        "\n",
        "    download_video(youtube_url, video_path)\n",
        "    convert_video_to_audio(video_path, audio_path)\n",
        "    text = transcribe_audio(audio_path)\n",
        "    analysis_results = analyze_content(text)\n",
        "\n",
        "    print(\"Analysis Results:\")\n",
        "    for key, result in analysis_results.items():\n",
        "        print(f\"{key}: {result}\")\n",
        "\n",
        "# Run the main function\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lWzvPTUEZ60",
        "outputId": "71785c7f-1d06-4208-c3dd-23beca0584d4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while downloading the video: HTTP Error 400: Bad Request\n",
            "An error occurred while converting video to audio: MoviePy error: the file video.mp4 could not be found!\n",
            "Please check that you entered the correct path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/wav2vec2-large-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred during audio transcription: [Errno 2] No such file or directory: 'audio.wav'\n",
            "Content analysis completed.\n",
            "Analysis Results:\n",
            "Highly Effective: [{'label': 'POSITIVE', 'score': 0.7481208443641663}]\n",
            "Effective: [{'label': 'POSITIVE', 'score': 0.7481208443641663}]\n",
            "Partially Effective: [{'label': 'POSITIVE', 'score': 0.7481208443641663}]\n",
            "Ineffective: [{'label': 'POSITIVE', 'score': 0.7481208443641663}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp\n"
      ],
      "metadata": {
        "id": "prAJR69BIDsm",
        "outputId": "726d54f4-2f02-4fd1-ad2e-b75a755065ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.8.6-py3-none-any.whl.metadata (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.1/170.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.7.4)\n",
            "Collecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests<3,>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.32.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt-dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.7)\n",
            "Downloading yt_dlp-2024.8.6-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.20.0 websockets-12.0 yt-dlp-2024.8.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yt_dlp\n",
        "\n",
        "def download_youtube_video(url, output_path):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo+bestaudio/best',\n",
        "        'outtmpl': output_path\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "    print(f\"Video downloaded to {output_path}\")\n",
        "\n",
        "# Example usage\n",
        "youtube_url = 'https://www.youtube.com/watch?v=ERIwByt4xc0'\n",
        "output_path = 'downloaded_video.mp4'\n",
        "download_youtube_video(youtube_url, output_path)\n"
      ],
      "metadata": {
        "id": "_mIk4BbzIF_q",
        "outputId": "517b20e2-a43d-4c19-827a-8e304294b468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=ERIwByt4xc0\n",
            "[youtube] ERIwByt4xc0: Downloading webpage\n",
            "[youtube] ERIwByt4xc0: Downloading ios player API JSON\n",
            "[youtube] ERIwByt4xc0: Downloading web creator player API JSON\n",
            "[youtube] ERIwByt4xc0: Downloading player 28fd7348\n",
            "[youtube] ERIwByt4xc0: Downloading m3u8 information\n",
            "[info] ERIwByt4xc0: Downloading 1 format(s): 247+251\n",
            "[download] Destination: downloaded_video.mp4.f247.webm\n",
            "[download] 100% of  293.73MiB in 00:01:05 at 4.48MiB/s   \n",
            "[download] Destination: downloaded_video.mp4.f251.webm\n",
            "[download] 100% of   37.60MiB in 00:00:01 at 31.93MiB/s  \n",
            "[Merger] Merging formats into \"downloaded_video.mp4.webm\"\n",
            "Deleting original file downloaded_video.mp4.f247.webm (pass -k to keep)\n",
            "Deleting original file downloaded_video.mp4.f251.webm (pass -k to keep)\n",
            "Video downloaded to downloaded_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def extract_frames(video_path, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_filename = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "        frame_count += 1\n",
        "    cap.release()\n",
        "    print(f\"Frames extracted to {output_folder}\")\n",
        "\n",
        "# Example usage\n",
        "output_folder = 'frames'\n",
        "extract_frames(output_path, output_folder)\n"
      ],
      "metadata": {
        "id": "fjqaTfpfIsCx",
        "outputId": "6221790f-fc28-40e2-8ddc-be9aec414165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames extracted to frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract Pillow\n",
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr\n"
      ],
      "metadata": {
        "id": "0B3FcXkzJg-P",
        "outputId": "55206879-69b9-49cc-89b5-4f6883b89be3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Ign:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [921 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,441 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,954 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,421 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,841 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,552 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,152 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,218 kB]\n",
            "Fetched 23.8 MB in 6s (4,145 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (9,647 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123594 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "def extract_text_from_frames(frame_folder):\n",
        "    texts = []\n",
        "    for filename in os.listdir(frame_folder):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(frame_folder, filename)\n",
        "            img = Image.open(img_path)\n",
        "            text = pytesseract.image_to_string(img)\n",
        "            texts.append(text)\n",
        "    return texts\n",
        "\n",
        "# Example usage\n",
        "texts = extract_text_from_frames(output_folder)\n"
      ],
      "metadata": {
        "id": "BcBZzrVXJXvs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the text generation pipeline with a publicly available model\n",
        "nlp = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "def generate_feedback(texts):\n",
        "    # Combine all texts extracted from frames\n",
        "    combined_text = \"\\n\".join(texts)\n",
        "\n",
        "    # Create a prompt for the model\n",
        "    prompt = f\"Analyze the following text content from video frames and provide feedback on lesson plans based on Performance Standard #1: Professional Knowledge.\\n\" \\\n",
        "             \"Criteria: Professional Educators prepare for quality instruction using a comprehensive approach.\\n\\n\" \\\n",
        "             \"Key Indicators:\\n\" \\\n",
        "             \"1b. Use school-adopted curriculum and Grade Level Expectations (GLEs) Colorado Academic Standards to design coherent lessons.\\n\\n\" \\\n",
        "             \"Performance Levels:\\n\" \\\n",
        "             \"Highly Effective: Lesson plans reflect a thorough integration of State standards and the STEM School PBL Instructional Model.\\n\" \\\n",
        "             \"Effective: Lesson plans closely align to STEM PBL Instructional Model and State standards.\\n\" \\\n",
        "             \"Partially Effective: Lesson plans are partially aligned to State standards, STEM PBL Instructional Model.\\n\" \\\n",
        "             \"Ineffective: Lesson plans are not readily available and/or do not align with State standards and STEM School PBL Instructional Model.\\n\\n\" \\\n",
        "             \"Extracted Text:\\n{combined_text}\\n\\n\" \\\n",
        "             \"Feedback based on the criteria and performance levels:\"\n",
        "\n",
        "    # Generate feedback\n",
        "    feedback = nlp(prompt, max_length=300, num_return_sequences=1)[0]['generated_text']\n",
        "\n",
        "    return feedback\n",
        "\n",
        "# Example usage\n",
        "texts = [\n",
        "    \"Frame 1: This lesson plan integrates State standards and follows the STEM PBL Instructional Model closely.\",\n",
        "    \"Frame 2: The curriculum aligns well with the Grade Level Expectations and State standards.\",\n",
        "    # Add more text data here\n",
        "]\n",
        "\n",
        "feedback = generate_feedback(texts)\n",
        "print(feedback)\n"
      ],
      "metadata": {
        "id": "dbZ2NEVFJaUA",
        "outputId": "ea508288-248c-40c7-dd79-6ae15e9233e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyze the following text content from video frames and provide feedback on lesson plans based on Performance Standard #1: Professional Knowledge.\n",
            "Criteria: Professional Educators prepare for quality instruction using a comprehensive approach.\n",
            "\n",
            "Key Indicators:\n",
            "1b. Use school-adopted curriculum and Grade Level Expectations (GLEs) Colorado Academic Standards to design coherent lessons.\n",
            "\n",
            "Performance Levels:\n",
            "Highly Effective: Lesson plans reflect a thorough integration of State standards and the STEM School PBL Instructional Model.\n",
            "Effective: Lesson plans closely align to STEM PBL Instructional Model and State standards.\n",
            "Partially Effective: Lesson plans are partially aligned to State standards, STEM PBL Instructional Model.\n",
            "Ineffective: Lesson plans are not readily available and/or do not align with State standards and STEM School PBL Instructional Model.\n",
            "\n",
            "Extracted Text:\n",
            "{combined_text}\n",
            "\n",
            "Feedback based on the criteria and performance levels: The following data indicates that this class provides the necessary corrective guidance that would benefit both the Colorado PBL and the Colorado PBL.\n",
            "Note:\n",
            "[0] We are not evaluating the teacher. We are not evaluating the parent. We are not evaluating the teacher. We are not evaluating the teacher. We are not evaluating the teacher.\n",
            "You can view the comments below below to ensure that all comments on this class are considered accurate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3tjq4bOFJ1Re"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}